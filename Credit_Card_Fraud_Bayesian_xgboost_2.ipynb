{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit_Card_Fraud_Bayesian_xgboost_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/jzIuO8flGGdg+S9kzPRD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohitkhannanu/ml-01/blob/master/Credit_Card_Fraud_Bayesian_xgboost_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcfdShwFFBRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install bayesian-optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQPWjHUoNMmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from datetime import datetime\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Bayesian Optimization\n",
        "#Importing necessary libraries\n",
        "from bayes_opt import BayesianOptimization\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVDH3egiEE1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Dataset\n",
        "data = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaFqnztAELyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data into X and y\n",
        "X = data.iloc[:,1:29]\n",
        "Y_cont = data.iloc[:,29]\n",
        "Y_class = data.iloc[:,30]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwiYcCqaHn7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create 3 datasets - In Sample, Hold out, Validation data\n",
        "# 70%, 15%, 15%\n",
        "# In Sample\n",
        "\n",
        "X_train, X_2, Y_cont_train, Y_cont_2, Y_class_train, Y_class_2 = train_test_split(X, Y_cont, Y_class, test_size=0.3, random_state=7)\n",
        "\n",
        "#X_train.shape #(199364, 28)\n",
        "#X_2.shape #(85443, 28)\n",
        "#Y_cont_train.shape #(199364,)\n",
        "#Y_cont_2.shape #(85443,)\n",
        "#Y_class_train.shape #(199364, 28)\n",
        "#Y_class_2.shape #(85443,)\n",
        "\n",
        "X_hold_out, X_val, Y_cont_hold_out, Y_cont_val, Y_class_hold_out, Y_class_val = train_test_split(X_2, Y_cont_2, Y_class_2, test_size=0.5, random_state=7)\n",
        "\n",
        "#X_hold_out.shape #(42721, 28)\n",
        "#X_val.shape #(42722, 28)\n",
        "#Y_cont_hold_out.shape #(42721,)\n",
        "#Y_cont_val.shape #(42722,)\n",
        "#Y_class_hold_out.shape #(42721, 28)\n",
        "#Y_class_val.shape #(42722,)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaKoHXd_-J3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "273caeb2-86b2-4493-b410-f87ac4d2f4a4"
      },
      "source": [
        "#Bayesian Optimization function for xgboost\n",
        "#specify the parameters you want to tune as keyword arguments\n",
        "starttime = datetime.now()\n",
        "def bo_tune_xgb(max_depth, n_estimators, learning_rate):\n",
        "    \"\"\"\n",
        "    params = {'max_depth': int(max_depth),\n",
        "              #'gamma': gamma,\n",
        "              'n_estimators': int(n_estimators),\n",
        "              'learning_rate':learning_rate,\n",
        "              #'subsample': 0.8,\n",
        "              #'eta': 0.1,\n",
        "              'eval_metric': 'error'}\n",
        "    \"\"\"\n",
        "    test_model = XGBClassifier(booster='gbtree',\n",
        "                  learning_rate=learning_rate, max_depth=int(max_depth),\n",
        "                  n_estimators=int(n_estimators), n_jobs=1,\n",
        "                  nthread=None, objective='binary:logistic', random_state=0,\n",
        "                  seed=None,\n",
        "                  silent=None,verbosity=1)\n",
        "    test_model.fit(X_train, Y_class_train)\n",
        "\n",
        "    #Return the accuracy\n",
        "    y_pred  = test_model.predict(X_hold_out)\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    #accuracy = accuracy_score(Y_class_hold_out, predictions)\n",
        "    ngini= gini_normalized(Y_class_hold_out, predictions)\n",
        "    return ngini\n",
        "    \n",
        "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
        "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (2,10),\n",
        "                                             #'gamma': (0, 1),\n",
        "                                             'learning_rate':(0.05, 0.3),\n",
        "                                             'n_estimators':(100,600)\n",
        "                                            })\n",
        "\n",
        "#performing Bayesian optimization for 5 iterations with 8 steps of random exploration with an #acquisition function of expected improvement\n",
        "xgb_bo.maximize(n_iter=15, init_points=10, acq='ei')\n",
        "\n",
        "#Extracting the best parameters\n",
        "params = xgb_bo.max['params']\n",
        "print(params)\n",
        "print(datetime.now() - starttime) #1:16:14.870691"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | learni... | max_depth | n_esti... |\n",
            "-------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.0899  \u001b[0m | \u001b[0m 2.434   \u001b[0m | \u001b[0m 235.9   \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8195  \u001b[0m | \u001b[95m 0.1029  \u001b[0m | \u001b[95m 2.638   \u001b[0m | \u001b[95m 284.0   \u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8296  \u001b[0m | \u001b[95m 0.2508  \u001b[0m | \u001b[95m 7.963   \u001b[0m | \u001b[95m 280.1   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.221   \u001b[0m | \u001b[0m 4.159   \u001b[0m | \u001b[0m 331.7   \u001b[0m |\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8481  \u001b[0m | \u001b[95m 0.2353  \u001b[0m | \u001b[95m 7.095   \u001b[0m | \u001b[95m 510.3   \u001b[0m |\n",
            "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.8481  \u001b[0m | \u001b[95m 0.2317  \u001b[0m | \u001b[95m 9.829   \u001b[0m | \u001b[95m 193.7   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.838   \u001b[0m | \u001b[0m 0.227   \u001b[0m | \u001b[0m 8.842   \u001b[0m | \u001b[0m 581.7   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.1106  \u001b[0m | \u001b[0m 3.161   \u001b[0m | \u001b[0m 524.1   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.1597  \u001b[0m | \u001b[0m 2.415   \u001b[0m | \u001b[0m 148.6   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.2431  \u001b[0m | \u001b[0m 5.032   \u001b[0m | \u001b[0m 529.7   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.2995  \u001b[0m | \u001b[0m 9.882   \u001b[0m | \u001b[0m 447.3   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8481  \u001b[0m | \u001b[0m 0.1637  \u001b[0m | \u001b[0m 7.066   \u001b[0m | \u001b[0m 192.4   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.838   \u001b[0m | \u001b[0m 0.2432  \u001b[0m | \u001b[0m 9.935   \u001b[0m | \u001b[0m 597.9   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.838   \u001b[0m | \u001b[0m 0.2258  \u001b[0m | \u001b[0m 9.98    \u001b[0m | \u001b[0m 489.7   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.838   \u001b[0m | \u001b[0m 0.08453 \u001b[0m | \u001b[0m 9.923   \u001b[0m | \u001b[0m 390.1   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.1583  \u001b[0m | \u001b[0m 9.814   \u001b[0m | \u001b[0m 100.1   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.838   \u001b[0m | \u001b[0m 0.1759  \u001b[0m | \u001b[0m 9.883   \u001b[0m | \u001b[0m 511.5   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8126  \u001b[0m | \u001b[0m 0.2801  \u001b[0m | \u001b[0m 2.07    \u001b[0m | \u001b[0m 414.0   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.2955  \u001b[0m | \u001b[0m 2.366   \u001b[0m | \u001b[0m 499.2   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.2874  \u001b[0m | \u001b[0m 2.037   \u001b[0m | \u001b[0m 598.6   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8434  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 308.9   \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8434  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 418.3   \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8229  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 170.3   \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8331  \u001b[0m | \u001b[0m 0.162   \u001b[0m | \u001b[0m 2.042   \u001b[0m | \u001b[0m 100.4   \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.2874  \u001b[0m | \u001b[0m 2.649   \u001b[0m | \u001b[0m 558.1   \u001b[0m |\n",
            "=============================================================\n",
            "{'learning_rate': 0.23168447688876614, 'max_depth': 9.82884044102936, 'n_estimators': 193.6557083061293}\n",
            "1:16:14.870691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbG26LPONzM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5a80bc1f-cf0d-4547-dcb2-9975d7c72e0c"
      },
      "source": [
        "#test accuracy\n",
        "model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "              learning_rate=0.23168447688876614, max_delta_step=0, max_depth=10,\n",
        "              min_child_weight=1, missing=None, n_estimators=194, n_jobs=1,\n",
        "              nthread=None, objective='binary:logistic', random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, subsample=1, verbosity=1)\n",
        "model.fit(X_train, Y_class_train)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.23168447688876614, max_delta_step=0, max_depth=10,\n",
              "              min_child_weight=1, missing=None, n_estimators=194, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMYq7l62UJ_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd23fe7c-d765-4fb2-e6bc-8dea1a6f60ef"
      },
      "source": [
        "# make predictions for test data\n",
        "y_pred  = model.predict(X_val)\n",
        "#y_pred  = model.predict(X_hold_out)\n",
        "#y_pred  = model.predict(X_train)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(Y_class_val, predictions)\n",
        "#accuracy = accuracy_score(Y_class_hold_out, predictions)\n",
        "#accuracy = accuracy_score(Y_class_train, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AePEpl6_WL1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gini definition\n",
        "def gini(actual, pred):\n",
        "    assert (len(actual) == len(pred))\n",
        "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
        "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
        "    totalLosses = all[:, 0].sum()\n",
        "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
        "\n",
        "    giniSum -= (len(actual) + 1) / 2.\n",
        "    return giniSum / len(actual)\n",
        "\n",
        "\n",
        "def gini_normalized(actual, pred):\n",
        "    return gini(actual, pred) / gini(actual, actual)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG1LnspnXYLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41b4009c-4d46-42fc-a44b-3439ea344a6d"
      },
      "source": [
        "# Gini calculations\n",
        "gini_predictions = gini(Y_class_val, predictions)\n",
        "gini_max = gini(Y_class_val, Y_class_val)\n",
        "ngini= gini_normalized(Y_class_val, predictions)\n",
        "\n",
        "#gini_predictions = gini(Y_class_hold_out, predictions)\n",
        "#gini_max = gini(Y_class_hold_out, Y_class_hold_out)\n",
        "#ngini= gini_normalized(Y_class_hold_out, predictions)\n",
        "\n",
        "#gini_predictions = gini(Y_class_train, predictions)\n",
        "#gini_max = gini(Y_class_train, Y_class_train)\n",
        "#ngini= gini_normalized(Y_class_train, predictions)\n",
        "\n",
        "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))\n",
        "\n",
        "# Grid Search results\n",
        "# In Sample------------------ 0.816\n",
        "# Hold Out------------------- 0.842\n",
        "# Val-------------------------0.783\n",
        "\n",
        "# Bayesian\n",
        "# Val-------------------------0.793"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gini: 0.396, Max. Gini: 0.499, Normalized Gini: 0.793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itGMlsMGbECF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gini Drop Hold Out to Val\n",
        "(0.783/0.842-1)*100"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}