{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit_Card_Fraud_Bayesian_xgboost_3 _Drop_Gini.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoQWmqzDWCzP6L1yVoeZNz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohitkhannanu/ml-01/blob/master/Credit_Card_Fraud_Bayesian_xgboost_3__Drop_Gini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcfdShwFFBRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install bayesian-optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQPWjHUoNMmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from datetime import datetime\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Bayesian Optimization\n",
        "# Importing necessary libraries\n",
        "from bayes_opt import BayesianOptimization\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVDH3egiEE1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Dataset\n",
        "data = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaFqnztAELyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data into X and y\n",
        "X = data.iloc[:,1:29]\n",
        "Y_cont = data.iloc[:,29]\n",
        "Y_class = data.iloc[:,30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwiYcCqaHn7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create 3 datasets - In Sample, Hold out, Validation data\n",
        "# 70%, 15%, 15%\n",
        "# In Sample\n",
        "\n",
        "X_train, X_2, Y_cont_train, Y_cont_2, Y_class_train, Y_class_2 = train_test_split(X, Y_cont, Y_class, test_size=0.3, random_state=7)\n",
        "\n",
        "# X_train.shape #(199364, 28)\n",
        "# X_2.shape #(85443, 28)\n",
        "# Y_cont_train.shape #(199364,)\n",
        "# Y_cont_2.shape #(85443,)\n",
        "# Y_class_train.shape #(199364, 28)\n",
        "# Y_class_2.shape #(85443,)\n",
        "\n",
        "X_hold_out, X_val, Y_cont_hold_out, Y_cont_val, Y_class_hold_out, Y_class_val = train_test_split(X_2, Y_cont_2, Y_class_2, test_size=0.5, random_state=7)\n",
        "\n",
        "# X_hold_out.shape #(42721, 28)\n",
        "# X_val.shape #(42722, 28)\n",
        "# Y_cont_hold_out.shape #(42721,)\n",
        "# Y_cont_val.shape #(42722,)\n",
        "# Y_class_hold_out.shape #(42721, 28)\n",
        "# Y_class_val.shape #(42722,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOORT9qYkSpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gini definition\n",
        "def gini(actual, pred):\n",
        "    assert (len(actual) == len(pred))\n",
        "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
        "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
        "    totalLosses = all[:, 0].sum()\n",
        "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
        "\n",
        "    giniSum -= (len(actual) + 1) / 2.\n",
        "    return giniSum / len(actual)\n",
        "\n",
        "\n",
        "def gini_normalized(actual, pred):\n",
        "    return gini(actual, pred) / gini(actual, actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaKoHXd_-J3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "23e1b573-db0b-40f0-e7cf-5e1c5f38ac06"
      },
      "source": [
        "# Bayesian Optimization function for xgboost\n",
        "# Specify the parameters you want to tune as keyword arguments\n",
        "starttime = datetime.now()\n",
        "def bo_tune_xgb(max_depth, n_estimators, learning_rate):\n",
        "    \"\"\"\n",
        "    params = {'max_depth': int(max_depth),\n",
        "              #'gamma': gamma,\n",
        "              'n_estimators': int(n_estimators),\n",
        "              'learning_rate':learning_rate,\n",
        "              #'subsample': 0.8,\n",
        "              #'eta': 0.1,\n",
        "              'eval_metric': 'error'}\n",
        "    \"\"\"\n",
        "    test_model = XGBClassifier(booster='gbtree',\n",
        "                  learning_rate=learning_rate, max_depth=int(max_depth),\n",
        "                  n_estimators=int(n_estimators), n_jobs=1,\n",
        "                  nthread=None, objective='binary:logistic', random_state=0,\n",
        "                  seed=None,\n",
        "                  silent=None,verbosity=1)\n",
        "    test_model.fit(X_train, Y_class_train)\n",
        "\n",
        "    #Return the Gini drop\n",
        "    \n",
        "    # Insample Gini\n",
        "    y_pred1  = test_model.predict(X_train)\n",
        "    predictions1 = [round(value) for value in y_pred1]\n",
        "    train_gini = gini_normalized(Y_class_train, predictions1)\n",
        "\n",
        "    # Hold Out sample Gini\n",
        "    y_pred2  = test_model.predict(X_hold_out)\n",
        "    predictions2 = [round(value) for value in y_pred2]\n",
        "    test_gini = gini_normalized(Y_class_hold_out, predictions2)\n",
        "\n",
        "    drop_gini = train_gini - test_gini # Drop in Gini across samples\n",
        "    return drop_gini * -1\n",
        "    \n",
        "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
        "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (2,10),\n",
        "                                             #'gamma': (0, 1),\n",
        "                                             'learning_rate':(0.05, 0.3),\n",
        "                                             'n_estimators':(100,600)\n",
        "                                            })\n",
        "\n",
        "#performing Bayesian optimization for 5 iterations with 8 steps of random exploration with an #acquisition function of expected improvement\n",
        "xgb_bo.maximize(n_iter=15, init_points=10, acq='ei')\n",
        "\n",
        "#Extracting the best parameters\n",
        "params = xgb_bo.max['params']\n",
        "print(params)\n",
        "print(datetime.now() - starttime) #0:57:46.245054"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | learni... | max_depth | n_esti... |\n",
            "-------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1677  \u001b[0m | \u001b[0m 0.07614 \u001b[0m | \u001b[0m 3.734   \u001b[0m | \u001b[0m 584.1   \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.162   \u001b[0m | \u001b[95m 0.234   \u001b[0m | \u001b[95m 9.599   \u001b[0m | \u001b[95m 508.7   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1805  \u001b[0m | \u001b[0m 0.0656  \u001b[0m | \u001b[0m 5.4     \u001b[0m | \u001b[0m 523.5   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1805  \u001b[0m | \u001b[0m 0.1234  \u001b[0m | \u001b[0m 4.157   \u001b[0m | \u001b[0m 305.3   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.162   \u001b[0m | \u001b[0m 0.07687 \u001b[0m | \u001b[0m 6.034   \u001b[0m | \u001b[0m 372.0   \u001b[0m |\n",
            "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.007567\u001b[0m | \u001b[95m 0.08268 \u001b[0m | \u001b[95m 2.798   \u001b[0m | \u001b[95m 328.9   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1704  \u001b[0m | \u001b[0m 0.2622  \u001b[0m | \u001b[0m 7.99    \u001b[0m | \u001b[0m 286.9   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.162   \u001b[0m | \u001b[0m 0.2694  \u001b[0m | \u001b[0m 9.298   \u001b[0m | \u001b[0m 325.7   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.154   \u001b[0m | \u001b[0m 0.2126  \u001b[0m | \u001b[0m 3.506   \u001b[0m | \u001b[0m 170.5   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.162   \u001b[0m | \u001b[0m 0.2494  \u001b[0m | \u001b[0m 4.744   \u001b[0m | \u001b[0m 532.1   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.004024\u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 231.9   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.003396\u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.002478\u001b[0m | \u001b[0m 0.1202  \u001b[0m | \u001b[0m 2.029   \u001b[0m | \u001b[0m 344.1   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1805  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 441.8   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.03636 \u001b[0m | \u001b[0m 0.2007  \u001b[0m | \u001b[0m 2.002   \u001b[0m | \u001b[0m 257.0   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.162   \u001b[0m | \u001b[0m 0.1412  \u001b[0m | \u001b[0m 5.246   \u001b[0m | \u001b[0m 421.5   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1752  \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 3.336   \u001b[0m | \u001b[0m 181.6   \u001b[0m |\n",
            "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.01251 \u001b[0m | \u001b[95m 0.3     \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 120.9   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.162   \u001b[0m | \u001b[0m 0.2433  \u001b[0m | \u001b[0m 9.847   \u001b[0m | \u001b[0m 126.6   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.004351\u001b[0m | \u001b[0m 0.1469  \u001b[0m | \u001b[0m 2.002   \u001b[0m | \u001b[0m 100.9   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1211  \u001b[0m | \u001b[0m 0.2392  \u001b[0m | \u001b[0m 2.03    \u001b[0m | \u001b[0m 333.0   \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.002851\u001b[0m | \u001b[0m 0.1396  \u001b[0m | \u001b[0m 3.914   \u001b[0m | \u001b[0m 121.4   \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.002197\u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 476.7   \u001b[0m |\n",
            "| \u001b[95m 24      \u001b[0m | \u001b[95m 0.02585 \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 355.6   \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1134  \u001b[0m | \u001b[0m 0.2355  \u001b[0m | \u001b[0m 2.171   \u001b[0m | \u001b[0m 319.1   \u001b[0m |\n",
            "=============================================================\n",
            "{'learning_rate': 0.05, 'max_depth': 2.0, 'n_estimators': 355.6009529095258}\n",
            "0:57:46.245054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbG26LPONzM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "a741a43b-27aa-47a3-91b2-1eef8e747e26"
      },
      "source": [
        "#test accuracy\n",
        "model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "              learning_rate=0.05, max_delta_step=0, max_depth=2,\n",
        "              min_child_weight=1, missing=None, n_estimators=356, n_jobs=1,\n",
        "              nthread=None, objective='binary:logistic', random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, subsample=1, verbosity=1)\n",
        "model.fit(X_train, Y_class_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.05, max_delta_step=0, max_depth=2,\n",
              "              min_child_weight=1, missing=None, n_estimators=356, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMYq7l62UJ_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "339eb30a-4868-466e-c598-fd2cfe69f41d"
      },
      "source": [
        "# make predictions for test data\n",
        "y_pred  = model.predict(X_val)\n",
        "#y_pred  = model.predict(X_hold_out)\n",
        "#y_pred  = model.predict(X_train)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(Y_class_val, predictions)\n",
        "#accuracy = accuracy_score(Y_class_hold_out, predictions)\n",
        "#accuracy = accuracy_score(Y_class_train, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG1LnspnXYLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fef2b69-ad30-4075-f32c-fb52315d466d"
      },
      "source": [
        "# Gini calculations\n",
        "gini_predictions = gini(Y_class_val, predictions)\n",
        "gini_max = gini(Y_class_val, Y_class_val)\n",
        "ngini= gini_normalized(Y_class_val, predictions)\n",
        "\n",
        "#gini_predictions = gini(Y_class_hold_out, predictions)\n",
        "#gini_max = gini(Y_class_hold_out, Y_class_hold_out)\n",
        "#ngini= gini_normalized(Y_class_hold_out, predictions)\n",
        "\n",
        "#gini_predictions = gini(Y_class_train, predictions)\n",
        "#gini_max = gini(Y_class_train, Y_class_train)\n",
        "#ngini= gini_normalized(Y_class_train, predictions)\n",
        "\n",
        "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))\n",
        "\n",
        "# Grid Search results\n",
        "# In Sample------------------ 0.816\n",
        "# Hold Out------------------- 0.842\n",
        "# Val-------------------------0.783\n",
        "\n",
        "# Bayesian\n",
        "# Val-------------------------0.770"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gini: 0.385, Max. Gini: 0.499, Normalized Gini: 0.770\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
