{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit_Card_Fraud_Bayesian_xgboost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKrumKNjl8smvucjXV4yi8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohitkhannanu/ml-01/blob/master/Credit_Card_Fraud_Bayesian_xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcfdShwFFBRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install bayesian-optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQPWjHUoNMmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from datetime import datetime\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Bayesian Optimization\n",
        "#Importing necessary libraries\n",
        "from bayes_opt import BayesianOptimization\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVDH3egiEE1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Dataset\n",
        "data = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaFqnztAELyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data into X and y\n",
        "X = data.iloc[:,1:29]\n",
        "Y_cont = data.iloc[:,29]\n",
        "Y_class = data.iloc[:,30]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwiYcCqaHn7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create 3 datasets - In Sample, Hold out, Validation data\n",
        "# 70%, 15%, 15%\n",
        "# In Sample\n",
        "\n",
        "X_train, X_2, Y_cont_train, Y_cont_2, Y_class_train, Y_class_2 = train_test_split(X, Y_cont, Y_class, test_size=0.3, random_state=7)\n",
        "\n",
        "#X_train.shape #(199364, 28)\n",
        "#X_2.shape #(85443, 28)\n",
        "#Y_cont_train.shape #(199364,)\n",
        "#Y_cont_2.shape #(85443,)\n",
        "#Y_class_train.shape #(199364, 28)\n",
        "#Y_class_2.shape #(85443,)\n",
        "\n",
        "X_hold_out, X_val, Y_cont_hold_out, Y_cont_val, Y_class_hold_out, Y_class_val = train_test_split(X_2, Y_cont_2, Y_class_2, test_size=0.5, random_state=7)\n",
        "\n",
        "#X_hold_out.shape #(42721, 28)\n",
        "#X_val.shape #(42722, 28)\n",
        "#Y_cont_hold_out.shape #(42721,)\n",
        "#Y_cont_val.shape #(42722,)\n",
        "#Y_class_hold_out.shape #(42721, 28)\n",
        "#Y_class_val.shape #(42722,)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaKoHXd_-J3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "53de4aeb-cacb-4dd1-d40f-99d7e768274a"
      },
      "source": [
        "#Bayesian Optimization function for xgboost\n",
        "#specify the parameters you want to tune as keyword arguments\n",
        "starttime = datetime.now()\n",
        "def bo_tune_xgb(max_depth, n_estimators, learning_rate):\n",
        "    \"\"\"\n",
        "    params = {'max_depth': int(max_depth),\n",
        "              #'gamma': gamma,\n",
        "              'n_estimators': int(n_estimators),\n",
        "              'learning_rate':learning_rate,\n",
        "              #'subsample': 0.8,\n",
        "              #'eta': 0.1,\n",
        "              'eval_metric': 'error'}\n",
        "    \"\"\"\n",
        "    test_model = XGBClassifier(booster='gbtree',\n",
        "                  learning_rate=learning_rate, max_depth=int(max_depth),\n",
        "                  n_estimators=int(n_estimators), n_jobs=1,\n",
        "                  nthread=None, objective='binary:logistic', random_state=0,\n",
        "                  seed=None,\n",
        "                  silent=None,verbosity=1)\n",
        "    test_model.fit(X_train, Y_class_train)\n",
        "\n",
        "    #Return the accuracy\n",
        "    y_pred  = test_model.predict(X_hold_out)\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(Y_class_hold_out, predictions)\n",
        "    return accuracy\n",
        "    \n",
        "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
        "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (2,3),\n",
        "                                             #'gamma': (0, 1),\n",
        "                                             'learning_rate':(0.05, 0.1),\n",
        "                                             'n_estimators':(100,300)\n",
        "                                            })\n",
        "\n",
        "#performing Bayesian optimization for 5 iterations with 8 steps of random exploration with an #acquisition function of expected improvement\n",
        "xgb_bo.maximize(n_iter=5, init_points=8, acq='ei')\n",
        "\n",
        "#Extracting the best parameters\n",
        "params = xgb_bo.max['params']\n",
        "print(params)\n",
        "print(datetime.now() - starttime) #0:14:53.266125"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | learni... | max_depth | n_esti... |\n",
            "-------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9996  \u001b[0m | \u001b[0m 0.09578 \u001b[0m | \u001b[0m 2.191   \u001b[0m | \u001b[0m 259.5   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9995  \u001b[0m | \u001b[0m 0.0728  \u001b[0m | \u001b[0m 2.149   \u001b[0m | \u001b[0m 209.1   \u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9996  \u001b[0m | \u001b[95m 0.08821 \u001b[0m | \u001b[95m 2.5     \u001b[0m | \u001b[95m 280.1   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9996  \u001b[0m | \u001b[0m 0.06724 \u001b[0m | \u001b[0m 2.756   \u001b[0m | \u001b[0m 284.5   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9996  \u001b[0m | \u001b[0m 0.09283 \u001b[0m | \u001b[0m 2.145   \u001b[0m | \u001b[0m 222.3   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9996  \u001b[0m | \u001b[0m 0.09114 \u001b[0m | \u001b[0m 2.382   \u001b[0m | \u001b[0m 292.4   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9995  \u001b[0m | \u001b[0m 0.09078 \u001b[0m | \u001b[0m 2.559   \u001b[0m | \u001b[0m 215.3   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9995  \u001b[0m | \u001b[0m 0.05068 \u001b[0m | \u001b[0m 2.54    \u001b[0m | \u001b[0m 268.7   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9994  \u001b[0m | \u001b[0m 0.06452 \u001b[0m | \u001b[0m 2.98    \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9993  \u001b[0m | \u001b[0m 0.07132 \u001b[0m | \u001b[0m 2.328   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
            "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.9996  \u001b[0m | \u001b[95m 0.09767 \u001b[0m | \u001b[95m 2.879   \u001b[0m | \u001b[95m 299.9   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9996  \u001b[0m | \u001b[0m 0.07091 \u001b[0m | \u001b[0m 2.832   \u001b[0m | \u001b[0m 299.9   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9993  \u001b[0m | \u001b[0m 0.06454 \u001b[0m | \u001b[0m 2.847   \u001b[0m | \u001b[0m 100.1   \u001b[0m |\n",
            "=============================================================\n",
            "{'learning_rate': 0.09766511228152483, 'max_depth': 2.878771339611865, 'n_estimators': 299.9448142400638}\n",
            "0:14:53.266125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbG26LPONzM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "23b2488a-a2ac-4182-e0b3-ec0d3f2a1068"
      },
      "source": [
        "#test accuracy\n",
        "model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "              learning_rate=0.09766511228152483, max_delta_step=0, max_depth=3,\n",
        "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
        "              nthread=None, objective='binary:logistic', random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, subsample=1, verbosity=1)\n",
        "model.fit(X_train, Y_class_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.09766511228152483, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMYq7l62UJ_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a6aed09-bec9-45c0-85a4-317221ec9255"
      },
      "source": [
        "# make predictions for test data\n",
        "y_pred  = model.predict(X_val)\n",
        "#y_pred  = model.predict(X_hold_out)\n",
        "#y_pred  = model.predict(X_train)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(Y_class_val, predictions)\n",
        "#accuracy = accuracy_score(Y_class_hold_out, predictions)\n",
        "#accuracy = accuracy_score(Y_class_train, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AePEpl6_WL1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gini definition\n",
        "def gini(actual, pred):\n",
        "    assert (len(actual) == len(pred))\n",
        "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
        "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
        "    totalLosses = all[:, 0].sum()\n",
        "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
        "\n",
        "    giniSum -= (len(actual) + 1) / 2.\n",
        "    return giniSum / len(actual)\n",
        "\n",
        "\n",
        "def gini_normalized(actual, pred):\n",
        "    return gini(actual, pred) / gini(actual, actual)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG1LnspnXYLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ab3d49e-7e13-4ff7-f988-23b2f41ba212"
      },
      "source": [
        "# Gini calculations\n",
        "gini_predictions = gini(Y_class_val, predictions)\n",
        "gini_max = gini(Y_class_val, Y_class_val)\n",
        "ngini= gini_normalized(Y_class_val, predictions)\n",
        "\n",
        "#gini_predictions = gini(Y_class_hold_out, predictions)\n",
        "#gini_max = gini(Y_class_hold_out, Y_class_hold_out)\n",
        "#ngini= gini_normalized(Y_class_hold_out, predictions)\n",
        "\n",
        "#gini_predictions = gini(Y_class_train, predictions)\n",
        "#gini_max = gini(Y_class_train, Y_class_train)\n",
        "#ngini= gini_normalized(Y_class_train, predictions)\n",
        "\n",
        "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))\n",
        "\n",
        "# Grid Search results\n",
        "# In Sample------------------ 0.816\n",
        "# Hold Out------------------- 0.842\n",
        "# Val-------------------------0.783\n",
        "\n",
        "# Bayesian\n",
        "# Val-------------------------0.783\n",
        "0.805"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gini: 0.402, Max. Gini: 0.499, Normalized Gini: 0.805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itGMlsMGbECF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6317bf9b-880c-4626-d95e-1aca1eade535"
      },
      "source": [
        "# Gini Drop Hold Out to Val\n",
        "(0.783/0.842-1)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-7.007125890736332"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}